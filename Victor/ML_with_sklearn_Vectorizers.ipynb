{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Keras/TF\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#SKLearn\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#NLTK Functions\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LogLoss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "data['title_tokenized'] = [word_tokenize(i) for i in data['Headline']]\n",
    "\n",
    "filtered = []\n",
    "for words in data['title_tokenized']:\n",
    "    temp = []\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            temp.append(w)\n",
    "    filtered.append(temp)\n",
    "\n",
    "data['title_no_stops'] = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound Score</th>\n",
       "      <th>Read/Fake</th>\n",
       "      <th>Character Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Upper Characters</th>\n",
       "      <th>Lower Case Characters</th>\n",
       "      <th>SpecialChar Count</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>title_no_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#2816: Clinton Pride’s 8(a) Pig Farm Bridge – ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>fake</td>\n",
       "      <td>97</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>[#, 2816, :, Clinton, Pride, ’, s, 8, (, a, ),...</td>\n",
       "      <td>[#, 2816, :, Clinton, Pride, ’, 8, (, ), Pig, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>#2817: Serco's Zulu Starnet Blackmail – Clinto...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>fake</td>\n",
       "      <td>88</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>[#, 2817, :, Serco, 's, Zulu, Starnet, Blackma...</td>\n",
       "      <td>[#, 2817, :, Serco, 's, Zulu, Starnet, Blackma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Roger Stone update on Stop the Steal exit poll...</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.713</td>\n",
       "      <td>-0.9313</td>\n",
       "      <td>fake</td>\n",
       "      <td>456</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>358</td>\n",
       "      <td>13</td>\n",
       "      <td>[Roger, Stone, update, on, Stop, the, Steal, e...</td>\n",
       "      <td>[Roger, Stone, update, Stop, Steal, exit, poll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>#2818: Serco's Zulu Bridge To Mumbai Pig Farm ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>fake</td>\n",
       "      <td>91</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>[#, 2818, :, Serco, 's, Zulu, Bridge, To, Mumb...</td>\n",
       "      <td>[#, 2818, :, Serco, 's, Zulu, Bridge, To, Mumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Trump Advocates the American People's Control ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>fake</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>[Trump, Advocates, the, American, People, 's, ...</td>\n",
       "      <td>[Trump, Advocates, American, People, 's, Contr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "2           2             2   \n",
       "3           3             3   \n",
       "4           4             4   \n",
       "\n",
       "                                            Headline  Negative  Positive  \\\n",
       "0  #2816: Clinton Pride’s 8(a) Pig Farm Bridge – ...     0.000      0.00   \n",
       "1  #2817: Serco's Zulu Starnet Blackmail – Clinto...     0.000      0.00   \n",
       "2  Roger Stone update on Stop the Steal exit poll...     0.237      0.05   \n",
       "3  #2818: Serco's Zulu Bridge To Mumbai Pig Farm ...     0.000      0.00   \n",
       "4  Trump Advocates the American People's Control ...     0.000      0.00   \n",
       "\n",
       "   Neutral  Compound Score Read/Fake  Character Count  Word Count  \\\n",
       "0    1.000          0.0000      fake               97          16   \n",
       "1    1.000          0.0000      fake               88          15   \n",
       "2    0.713         -0.9313      fake              456          72   \n",
       "3    1.000          0.0000      fake               91          17   \n",
       "4    1.000          0.0000      fake               66           9   \n",
       "\n",
       "   Upper Characters  Lower Case Characters  SpecialChar Count  \\\n",
       "0                13                     56                  8   \n",
       "1                11                     51                  7   \n",
       "2                14                    358                 13   \n",
       "3                12                     47                  8   \n",
       "4                 9                     46                  3   \n",
       "\n",
       "                                     title_tokenized  \\\n",
       "0  [#, 2816, :, Clinton, Pride, ’, s, 8, (, a, ),...   \n",
       "1  [#, 2817, :, Serco, 's, Zulu, Starnet, Blackma...   \n",
       "2  [Roger, Stone, update, on, Stop, the, Steal, e...   \n",
       "3  [#, 2818, :, Serco, 's, Zulu, Bridge, To, Mumb...   \n",
       "4  [Trump, Advocates, the, American, People, 's, ...   \n",
       "\n",
       "                                      title_no_stops  \n",
       "0  [#, 2816, :, Clinton, Pride, ’, 8, (, ), Pig, ...  \n",
       "1  [#, 2817, :, Serco, 's, Zulu, Starnet, Blackma...  \n",
       "2  [Roger, Stone, update, Stop, Steal, exit, poll...  \n",
       "3  [#, 2818, :, Serco, 's, Zulu, Bridge, To, Mumb...  \n",
       "4  [Trump, Advocates, American, People, 's, Contr...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode y's and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data['Read/Fake'].values)\n",
    "X = data['Headline'].values\n",
    "X_feat = data[['Negative','Positive','Neutral','Character Count','Word Count','Upper Characters','Lower Case Characters','SpecialChar Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfeattrain, xfeatvalid, ytrain, yvalid = train_test_split(X_feat, y, stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use OOTB Vectorizer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Function Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.355 \n",
      "[[1331  330]\n",
      " [ 216 2102]]\n",
      "Score: 0.8627795928625283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victor/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on TF-IDF\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "predictions_y = clf.predict(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))\n",
    "print (confusion_matrix(yvalid,predictions_y))\n",
    "print (f'Score: {clf.score(xvalid_tfv,yvalid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.563 \n",
      "[[ 856  805]\n",
      " [ 210 2108]]\n",
      "Score: 0.744910781603418\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on Features\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xfeattrain, ytrain)\n",
    "predictions = clf.predict_proba(xfeatvalid)\n",
    "predictions_y = clf.predict(xfeatvalid)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))\n",
    "print (confusion_matrix(yvalid,predictions_y))\n",
    "print (f'Score: {clf.score(xfeatvalid,yvalid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.329 \n",
      "[[1324  337]\n",
      " [ 195 2123]]\n",
      "Score: 0.8662980648404122\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on TFIDF\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "predictions_y = clf.predict(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))\n",
    "print (confusion_matrix(yvalid,predictions_y))\n",
    "print (f'Score: {clf.score(xvalid_tfv,yvalid)}')\n",
    "# print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.708 \n",
      "[[ 907  754]\n",
      " [ 443 1875]]\n",
      "Score: 0.6991706458909274\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on Features\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xfeattrain, ytrain)\n",
    "predictions = clf.predict_proba(xfeatvalid)\n",
    "predictions_y = clf.predict(xfeatvalid)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))\n",
    "print (confusion_matrix(yvalid,predictions_y))\n",
    "print (f'Score: {clf.score(xfeatvalid,yvalid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG BOOOOOOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.459 \n",
      "[[ 975  686]\n",
      " [ 161 2157]]\n",
      "Score: 0.7871324453380246\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_tfv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv.tocsc())\n",
    "predictions_y = clf.predict(xvalid_tfv.tocsc())\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))\n",
    "print (confusion_matrix(yvalid,predictions_y))\n",
    "print (f'Score: {clf.score(xvalid_tfv,yvalid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.418 \n",
      "[[1122  539]\n",
      " [ 211 2107]]\n",
      "Score: 0.8115104297562201\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on Features\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xfeattrain, ytrain)\n",
    "predictions = clf.predict_proba(xfeatvalid)\n",
    "predictions_y = clf.predict(xfeatvalid)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))\n",
    "print (confusion_matrix(yvalid,predictions_y))\n",
    "print (f'Score: {clf.score(xfeatvalid,yvalid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakes = data[data['Read/Fake']=='fake'].Headline\n",
    "reals = data[data['Read/Fake']=='real'].Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueify(listofstrings):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    unique = []\n",
    "    for item in listofstrings:\n",
    "        temp = tokenizer.tokenize(item)\n",
    "        for s in temp:\n",
    "            if (s.lower() not in stop_words and s.lower() not in unique):\n",
    "                unique.append(s.lower())\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenify(listofstrings):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    flat = []\n",
    "    for item in listofstrings:\n",
    "        temp = tokenizer.tokenize(item)\n",
    "        for s in temp:\n",
    "            if s.lower() not in stop_words:\n",
    "                flat.append(s.lower())\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_fakes = flattenify(fakes)\n",
    "flat_reals = flattenify(reals)\n",
    "unique_fakes = uniqueify(fakes)\n",
    "unique_reals = uniqueify(reals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakecounts = []\n",
    "realcounts = []\n",
    "\n",
    "for i in unique_fakes:\n",
    "    fcount = 0\n",
    "    for j in flat_fakes:\n",
    "        if i == j:\n",
    "            fcount = fcount + 1\n",
    "    fakecounts.append(fcount)\n",
    "    \n",
    "for i in unique_reals:\n",
    "    rcount = 0 \n",
    "    for j in flat_reals:\n",
    "        if i == j:\n",
    "            rcount = rcount + 1\n",
    "    realcounts.append(rcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakesdf = pd.DataFrame({'unique_fakes':unique_fakes, 'fake_counts':fakecounts})\n",
    "realsdf = pd.DataFrame({'unique_reals':unique_reals, 'real_counts':realcounts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakesdf = fakesdf.sort_values(by = 'fake_counts', ascending = False)\n",
    "realsdf = realsdf.sort_values(by = 'real_counts', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_fakes</th>\n",
       "      <th>fake_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>trump</td>\n",
       "      <td>1797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>hillary</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinton</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>new</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>election</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>us</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>video</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>man</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>news</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>russia</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_fakes  fake_counts\n",
       "71         trump         1797\n",
       "48       hillary         1020\n",
       "1        clinton          902\n",
       "350          new          890\n",
       "52      election          512\n",
       "51            us          498\n",
       "313        video          497\n",
       "450          man          477\n",
       "154         news          471\n",
       "263       russia          412"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakesdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_reals</th>\n",
       "      <th>real_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>u</td>\n",
       "      <td>2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>trump</td>\n",
       "      <td>2107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>says</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>korea</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>paid</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>notice</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>north</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>deaths</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>china</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_reals  real_counts\n",
       "96              u         2948\n",
       "672         trump         2107\n",
       "183          says         1776\n",
       "9             new         1278\n",
       "2994        korea         1032\n",
       "107          paid         1021\n",
       "108        notice         1011\n",
       "618         north          983\n",
       "113        deaths          920\n",
       "627         china          632"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realsdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakesdf.to_csv('./fakesdf_wordcloud.csv')\n",
    "realsdf.to_csv('./realsdf_wordcloud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
